{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 75346\n"
     ]
    }
   ],
   "source": [
    "with open(\"corpus.txt\", encoding=\"utf8\") as fin:\n",
    "    text = fin.read()\n",
    "print(\"Number of characters: %d\" % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental text processing (Last week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hhhuang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Number of tokens: 11781\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "raw_tokens = word_tokenize(text)\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "#stopword_list = stopwords.words('english')\n",
    "\n",
    "tokens = []\n",
    "for token in raw_tokens:\n",
    "    if token.isalpha():\n",
    "        tokens.append(token.lower())\n",
    "print(\"Number of tokens: %d\" % len(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\t1167\n",
      "of\t801\n",
      "and\t360\n",
      "in\t299\n",
      "to\t279\n",
      "a\t173\n",
      "is\t138\n",
      "that\t128\n",
      "by\t123\n",
      "class\t104\n",
      "with\t101\n",
      "it\t100\n",
      "bourgeois\t99\n",
      "all\t98\n",
      "bourgeoisie\t92\n",
      "as\t86\n",
      "for\t84\n",
      "they\t83\n",
      "its\t81\n",
      "their\t80\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter(tokens)\n",
    "for w, c in word_counts.most_common(20):\n",
    "    print(\"%s\\t%d\" % (w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tthe\t244\n",
      "in\tthe\t91\n",
      "the\tbourgeoisie\t66\n",
      "the\tproletariat\t50\n",
      "to\tthe\t43\n",
      "by\tthe\t40\n",
      "for\tthe\t38\n",
      "of\tproduction\t38\n",
      "with\tthe\t34\n",
      "the\tbourgeois\t33\n",
      "conditions\tof\t29\n",
      "means\tof\t25\n",
      "of\tsociety\t24\n",
      "on\tthe\t23\n",
      "against\tthe\t23\n",
      "working\tclass\t23\n",
      "to\tbe\t22\n",
      "of\tall\t22\n",
      "of\ta\t21\n",
      "the\told\t21\n"
     ]
    }
   ],
   "source": [
    "word_pair_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "    word_pair_counts[(w1, w2)] += 1\n",
    "    \n",
    "for pair, c in word_pair_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (pair[0], pair[1], c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the content in word_pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 244)\n"
     ]
    }
   ],
   "source": [
    "print(word_pair_counts.most_common(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "print(word_pair_counts[('of', 'the')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative way to get the contents in the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tthe\t244\n",
      "in\tthe\t91\n",
      "the\tbourgeoisie\t66\n",
      "the\tproletariat\t50\n",
      "to\tthe\t43\n",
      "by\tthe\t40\n",
      "for\tthe\t38\n",
      "of\tproduction\t38\n",
      "with\tthe\t34\n",
      "the\tbourgeois\t33\n",
      "conditions\tof\t29\n",
      "means\tof\t25\n",
      "of\tsociety\t24\n",
      "on\tthe\t23\n",
      "against\tthe\t23\n",
      "working\tclass\t23\n",
      "to\tbe\t22\n",
      "of\tall\t22\n",
      "of\ta\t21\n",
      "the\told\t21\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), c in word_pair_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (w1, w2, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hhhuang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "working\tclass\t23\n",
      "bourgeois\tsociety\t15\n",
      "class\tantagonisms\t11\n",
      "ruling\tclass\t11\n",
      "modern\tindustry\t11\n",
      "productive\tforces\t9\n",
      "modern\tbourgeois\t8\n",
      "middle\tages\t7\n",
      "private\tproperty\t7\n",
      "bourgeois\tproperty\t7\n",
      "class\tstruggle\t6\n",
      "old\tsociety\t6\n",
      "property\trelations\t6\n",
      "social\tconditions\t6\n",
      "middle\tclass\t6\n",
      "feudal\tsociety\t6\n",
      "petty\tbourgeois\t6\n",
      "existing\tsociety\t5\n",
      "bourgeois\tsocialism\t5\n",
      "one\tword\t5\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "word_pair_nosw_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "    if w1 not in stopword_list and w2 not in stopword_list:\n",
    "        word_pair_nosw_counts[(w1, w2)] += 1\n",
    "    \n",
    "for (w1, w2), c in word_pair_nosw_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (w1, w2, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent collocations with a distance of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\tof\t2\t302\n",
      "of\tthe\t1\t244\n",
      "the\tthe\t3\t186\n",
      "the\tthe\t8\t134\n",
      "the\tthe\t6\t129\n",
      "the\tthe\t7\t126\n",
      "the\tof\t3\t125\n",
      "the\tthe\t4\t117\n",
      "the\tthe\t5\t114\n",
      "of\tthe\t4\t92\n",
      "of\tthe\t8\t91\n",
      "in\tthe\t1\t91\n",
      "of\tthe\t6\t88\n",
      "the\tof\t7\t81\n",
      "the\tof\t6\t77\n",
      "the\tof\t5\t76\n",
      "of\tthe\t7\t76\n",
      "the\tof\t8\t75\n",
      "of\tthe\t5\t72\n",
      "the\tbourgeoisie\t1\t66\n"
     ]
    }
   ],
   "source": [
    "window_size = 9\n",
    "\n",
    "word_pair_counts = Counter()\n",
    "word_pair_distance_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    for distance in range(1, window_size):\n",
    "        if i + distance < len(tokens):\n",
    "            w1 = tokens[i]\n",
    "            w2 = tokens[i + distance]\n",
    "            word_pair_distance_counts[(w1, w2, distance)] += 1\n",
    "            word_pair_counts[(w1, w2)] += 1\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%d\" % (w1, w2, distance, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an entry in word_pair_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('the', 'of', 2), 302)\n",
      "3\n",
      "0\n",
      "Occurrences of the word pair (the, of) with a distance of 1: 3\n",
      "Occurrences of the word pair (the, of) with a distance of 2: 302\n",
      "Occurrences of the word pair (the, of) with a distance of 3: 125\n",
      "Occurrences of the word pair (the, of) with a distance of 4: 59\n",
      "Occurrences of the word pair (the, of) with a distance of 5: 76\n",
      "Occurrences of the word pair (the, of) with a distance of 6: 77\n",
      "Occurrences of the word pair (the, of) with a distance of 7: 81\n",
      "Occurrences of the word pair (the, of) with a distance of 8: 75\n",
      "Occurrences of the usage 'the * * of'\n",
      "302\n",
      "Occurrences of the usage 'of * * the'\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(word_pair_distance_counts.most_common(1)[0])\n",
    "\n",
    "print(word_pair_distance_counts['the', 'of', 1])\n",
    "print(word_pair_distance_counts['the', 'of', 100])\n",
    "\n",
    "\n",
    "for distance in range(1, window_size):\n",
    "    print(\"Occurrences of the word pair (%s, %s) with a distance of %d: %d\" % (\n",
    "        'the', 'of', distance, word_pair_distance_counts['the', 'of', distance]))\n",
    "\n",
    "print(\"Occurrences of the usage 'the * * of'\")\n",
    "print(word_pair_distance_counts['the', 'of', 2])\n",
    "\n",
    "print(\"Occurrences of the usage 'of * * the'\")\n",
    "print(word_pair_distance_counts['of', 'the', 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the collocations with mean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proletariat\tincrease\t8.000000\t1\n",
      "and\tchagrin\t8.000000\t1\n",
      "can\tdespotic\t8.000000\t1\n",
      "hand\tother\t8.000000\t1\n",
      "free\tit\t8.000000\t1\n",
      "concentrated\tconsequence\t8.000000\t1\n",
      "we\tnations\t8.000000\t1\n",
      "of\treproduce\t8.000000\t1\n",
      "appropriation\tincrease\t8.000000\t1\n",
      "coming\thalf\t8.000000\t1\n",
      "requiring\tlands\t8.000000\t1\n",
      "german\topposition\t8.000000\t1\n",
      "literature\tfrench\t8.000000\t1\n",
      "levelling\tcommunist\t8.000000\t1\n",
      "rule\tmore\t8.000000\t1\n",
      "the\tcastles\t8.000000\t1\n",
      "character\tloses\t8.000000\t1\n",
      "bourgeoisie\tparticular\t8.000000\t1\n",
      "victory\tby\t8.000000\t1\n",
      "ages\tfitting\t8.000000\t1\n"
     ]
    }
   ],
   "source": [
    "pair_mean_distances = Counter()\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    pair_mean_distances[(w1, w2)] += distance * (c / word_pair_counts[(w1, w2)])\n",
    "\n",
    "for (w1, w2), distance in pair_mean_distances.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering one-time cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\tseriously\t8.000000\t2\n",
      "only\tis\t8.000000\t2\n",
      "with\twhat\t8.000000\t2\n",
      "germany\timmediately\t8.000000\t2\n",
      "to\tpetty\t8.000000\t3\n",
      "lose\tto\t8.000000\t2\n",
      "ideas\tideas\t8.000000\t2\n",
      "at\tproperty\t8.000000\t2\n",
      "and\tmovements\t8.000000\t2\n",
      "an\teach\t8.000000\t2\n",
      "and\tphrases\t8.000000\t2\n",
      "disposal\tthe\t8.000000\t2\n",
      "in\tcommunistic\t8.000000\t2\n",
      "human\tto\t8.000000\t2\n",
      "is\tslave\t8.000000\t2\n",
      "by\tover\t8.000000\t2\n",
      "a\tinstead\t8.000000\t2\n",
      "class\tworking\t8.000000\t2\n",
      "they\tfuture\t8.000000\t2\n",
      "and\taristocracy\t8.000000\t2\n"
     ]
    }
   ],
   "source": [
    "pair_mean_distances = Counter()\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 1:\n",
    "        pair_mean_distances[(w1, w2)] += distance * (c / word_pair_counts[(w1, w2)])\n",
    "\n",
    "for (w1, w2), distance in pair_mean_distances.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\ttimes\t1.000000\t2\n",
      "have\talready\t1.000000\t2\n",
      "they\twrote\t1.000000\t3\n",
      "breaks\tout\t1.000000\t3\n",
      "which\tit\t1.000000\t5\n",
      "struggle\tbetween\t1.000000\t2\n",
      "contact\twith\t1.000000\t2\n",
      "political\tsupremacy\t1.000000\t3\n",
      "result\tfrom\t1.000000\t2\n",
      "bare\texistence\t1.000000\t2\n",
      "need\tto\t1.000000\t2\n",
      "family\trelations\t1.000000\t2\n",
      "chiefly\tto\t1.000000\t2\n",
      "be\teffected\t1.000000\t2\n",
      "head\tof\t1.000000\t2\n",
      "the\trest\t1.000000\t3\n",
      "association\tin\t1.000000\t2\n",
      "process\tof\t1.000000\t2\n",
      "yet\tin\t1.000000\t2\n",
      "in\tcontact\t1.000000\t2\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), distance in pair_mean_distances.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "became\tof\t4.500000\t2\n",
      "bourgeois\tbut\t4.500000\t6\n",
      "become\tand\t4.500000\t4\n",
      "can\titself\t4.500000\t2\n",
      "taking\tthe\t4.500000\t2\n",
      "preaching\tto\t4.500000\t2\n",
      "and\taway\t4.500000\t4\n",
      "develops\tthey\t4.500000\t2\n",
      "has\texploitation\t4.500000\t2\n",
      "cultivation\tof\t4.500000\t4\n",
      "superseded\tof\t4.500000\t2\n",
      "pauper\tand\t4.500000\t2\n",
      "the\treformers\t4.500000\t2\n",
      "agriculture\tindustries\t4.500000\t2\n",
      "vanishing\tthe\t4.500000\t2\n",
      "they\tovercome\t4.500000\t2\n",
      "oppressed\tthe\t4.500000\t2\n",
      "ended\tthe\t4.500000\t2\n",
      "there\tany\t4.500000\t2\n",
      "proletariat\tsee\t4.500000\t2\n"
     ]
    }
   ],
   "source": [
    "num_pairs = len(pair_mean_distances)\n",
    "mid = num_pairs // 2\n",
    "for (w1, w2), distance in pair_mean_distances.most_common()[mid-10:mid+10]:\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with offset deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what\tits\t4.500000\t4.949747\t2\n",
      "subjection\tof\t4.500000\t4.949747\t2\n",
      "yearnings\tof\t4.500000\t4.949747\t2\n",
      "ones\tthat\t4.500000\t4.949747\t2\n",
      "in\tland\t4.500000\t4.949747\t2\n",
      "way\tbeen\t4.500000\t4.949747\t2\n",
      "dangerous\tclass\t4.500000\t4.949747\t2\n",
      "of\tchemistry\t4.500000\t4.949747\t2\n",
      "political\tconditions\t4.500000\t4.949747\t2\n",
      "consciousness\tof\t4.500000\t4.949747\t2\n",
      "epochs\tof\t4.500000\t4.949747\t2\n",
      "fight\tfor\t4.500000\t4.949747\t2\n",
      "all\twork\t4.500000\t4.949747\t2\n",
      "and\tabove\t4.500000\t4.949747\t2\n",
      "the\tstandpoint\t4.500000\t4.949747\t2\n",
      "form\tthere\t4.500000\t4.949747\t2\n",
      "crime\twe\t4.500000\t4.949747\t2\n",
      "old\tbourgeois\t4.500000\t4.949747\t2\n",
      "in\tshowing\t4.500000\t4.949747\t2\n",
      "practically\tthe\t4.500000\t4.949747\t2\n"
     ]
    }
   ],
   "source": [
    "pair_deviations = Counter()\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 1:\n",
    "        pair_deviations[(w1, w2)] += c * ((distance - pair_mean_distances[(w1, w2)]) ** 2)\n",
    "    \n",
    "for (w1, w2), dev_tmp in pair_deviations.most_common():\n",
    "    s_2 = dev_tmp / (word_pair_counts[(w1, w2)] - 1)\n",
    "    pair_deviations[(w1, w2)] = s_2 ** 0.5\n",
    "    \n",
    "for (w1, w2), dev in pair_deviations.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but\twill\t2.000000\t0.000000\t2\n",
      "result\tfrom\t1.000000\t0.000000\t2\n",
      "bare\texistence\t1.000000\t0.000000\t2\n",
      "can\tcapital\t6.000000\t0.000000\t2\n",
      "our\trelations\t8.000000\t0.000000\t2\n",
      "the\tcentralization\t7.000000\t0.000000\t2\n",
      "need\tto\t1.000000\t0.000000\t2\n",
      "family\trelations\t1.000000\t0.000000\t2\n",
      "revolutionary\tagainst\t2.000000\t0.000000\t2\n",
      "chiefly\tto\t1.000000\t0.000000\t2\n",
      "be\teffected\t1.000000\t0.000000\t2\n",
      "is\tyet\t2.000000\t0.000000\t2\n",
      "form\tproperty\t2.000000\t0.000000\t4\n",
      "head\tof\t1.000000\t0.000000\t2\n",
      "the\trest\t1.000000\t0.000000\t3\n",
      "association\tin\t1.000000\t0.000000\t2\n",
      "time\tthis\t6.000000\t0.000000\t2\n",
      "process\tof\t1.000000\t0.000000\t2\n",
      "yet\tin\t1.000000\t0.000000\t2\n",
      "in\tcontact\t1.000000\t0.000000\t2\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), dev in pair_deviations.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher supportive threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\tand\t3.833333\t1.466804\t12\n",
      "have\tof\t5.869565\t1.455533\t23\n",
      "to\tbe\t1.416667\t1.442120\t24\n",
      "the\tcommunism\t4.454545\t1.439697\t11\n",
      "of\tcan\t5.000000\t1.414214\t11\n",
      "in\tbut\t5.000000\t1.414214\t11\n",
      "for\ta\t2.076923\t1.382120\t13\n",
      "for\tclass\t5.363636\t1.361817\t11\n",
      "as\tand\t5.153846\t1.344504\t13\n",
      "has\tof\t5.730769\t1.343360\t26\n",
      "it\thas\t1.409091\t1.333063\t22\n",
      "working\tclass\t1.360000\t1.319091\t25\n",
      "in\tclass\t5.272727\t1.272078\t11\n",
      "bourgeois\tsociety\t1.312500\t1.250000\t16\n",
      "it\tof\t6.088235\t1.239933\t34\n",
      "by\tmeans\t1.692308\t0.947331\t13\n",
      "in\tproportion\t1.500000\t0.904534\t12\n",
      "they\tare\t1.250000\t0.866025\t12\n",
      "modern\tindustry\t1.166667\t0.577350\t12\n",
      "ruling\tclass\t1.000000\t0.000000\t11\n"
     ]
    }
   ],
   "source": [
    "pair_deviations = Counter()\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 10:\n",
    "        pair_deviations[(w1, w2)] += c * ((distance - pair_mean_distances[(w1, w2)]) ** 2)\n",
    "    \n",
    "for (w1, w2), dev_tmp in pair_deviations.most_common():\n",
    "    s_2 = dev_tmp / (word_pair_counts[(w1, w2)] - 1)\n",
    "    pair_deviations[(w1, w2)] = s_2 ** 0.5\n",
    "    \n",
    "for (w1, w2), dev in pair_deviations.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's Chi-Square Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_pair_counts = Counter()\n",
    "word_counts = Counter(tokens)\n",
    "num_bigrams = 0\n",
    "\n",
    "for i in range(len(tokens) - 1):\n",
    "    w1 = tokens[i]\n",
    "    w2 = tokens[i + 1]\n",
    "    word_pair_counts[(w1, w2)] += 1\n",
    "    num_bigrams += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chisquare(o11, o12, o21, o22):\n",
    "    n = o11 + o12 + o21 + o22\n",
    "    x_2 = (n * ((o11 * o22 - o12 * o21)**2)) / ((o11 + o12) * (o11 + o21) * (o12 + o22) * (o21 + o22)) \n",
    "    return x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the chi-squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danish\tlanguages\t1\t11780.000000\n",
      "fanatics\thole\t1\t11780.000000\n",
      "battles\tlies\t1\t11780.000000\n",
      "egotistical\tcalculation\t1\t11780.000000\n",
      "greatest\tpleasure\t1\t11780.000000\n",
      "duodecimo\teditions\t1\t11780.000000\n",
      "decisive\thour\t1\t11780.000000\n",
      "nursery\ttale\t1\t11780.000000\n",
      "czar\tmetternich\t1\t11780.000000\n",
      "instinctive\tyearnings\t1\t11780.000000\n",
      "numberless\tindefeasible\t1\t11780.000000\n",
      "trades\tunions\t1\t11780.000000\n",
      "remotest\tzones\t1\t11780.000000\n",
      "establish\tconnections\t1\t11780.000000\n",
      "gothic\tcathedrals\t1\t11780.000000\n",
      "deep\tintuition\t1\t11780.000000\n",
      "singing\tlampoons\t1\t11780.000000\n",
      "proper\tserving\t1\t11780.000000\n",
      "arouse\tsympathy\t1\t11780.000000\n",
      "sentimental\tveil\t1\t11780.000000\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    w1_only_count = word_counts[w1] - w1_w2_count\n",
    "    w2_only_count = word_counts[w2] - w1_w2_count\n",
    "    rest_count = num_bigrams - w1_only_count - w2_only_count - w1_w2_count\n",
    "    pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on more frequent bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productive\tforces\t9\t9636.544203\n",
      "middle\tages\t7\t4928.714781\n",
      "no\tlonger\t14\t4150.496033\n",
      "working\tclass\t23\t2477.732678\n",
      "modern\tindustry\t11\t1128.037662\n",
      "class\tantagonisms\t11\t1042.736309\n",
      "private\tproperty\t7\t1022.522314\n",
      "ruling\tclass\t11\t966.767323\n",
      "can\tnot\t9\t775.745125\n",
      "their\town\t11\t759.449519\n",
      "proportion\tas\t8\t720.619853\n",
      "have\tbeen\t7\t702.438620\n",
      "it\thas\t20\t652.817376\n",
      "away\twith\t8\t563.758348\n",
      "to\tbe\t22\t468.075784\n",
      "just\tas\t6\t439.987822\n",
      "of\tthe\t244\t406.859323\n",
      "the\tbourgeoisie\t66\t397.199063\n",
      "its\town\t8\t392.296908\n",
      "petty\tbourgeois\t6\t381.069314\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 5:\n",
    "        w1_only_count = word_counts[w1] - w1_w2_count\n",
    "        w2_only_count = word_counts[w2] - w1_w2_count\n",
    "        rest_count = total - w1_only_count - w2_only_count - w1_w2_count\n",
    "        pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\tthe\t21\t4.412587\n",
      "and\tby\t7\t2.913108\n",
      "at\tthe\t7\t2.592918\n",
      "and\tthat\t7\t2.542680\n",
      "be\tthe\t7\t2.367553\n",
      "proletariat\tthe\t10\t2.357617\n",
      "bourgeois\tthe\t6\t1.654642\n",
      "that\tof\t6\t0.910970\n",
      "and\tof\t20\t0.906966\n",
      "of\tclass\t9\t0.569228\n",
      "bourgeoisie\tthe\t7\t0.548588\n",
      "that\tthe\t15\t0.476118\n",
      "of\tits\t7\t0.436822\n",
      "and\tin\t11\t0.401790\n",
      "society\tthe\t6\t0.307430\n",
      "all\tthe\t11\t0.192300\n",
      "the\tproperty\t6\t0.041125\n",
      "and\tto\t9\t0.027804\n",
      "the\tclass\t10\t0.009971\n",
      "class\tthe\t10\t0.009971\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), x_2 in pair_chi_squares.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filtering out the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\testate\t2\t11780.000000\n",
      "constitution\tadapted\t2\t11780.000000\n",
      "productive\tforces\t9\t9636.544203\n",
      "eternal\ttruths\t3\t8834.249809\n",
      "corporate\tguilds\t2\t7852.666553\n",
      "absolute\tmonarchy\t4\t7537.599406\n",
      "eighteenth\tcentury\t3\t7066.799694\n",
      "immense\tmajority\t3\t6624.749575\n",
      "laid\tbare\t2\t5888.999830\n",
      "distinctive\tfeature\t2\t5234.221968\n",
      "torn\tasunder\t2\t5234.221968\n",
      "middle\tages\t7\t4928.714781\n",
      "radical\trupture\t2\t4710.799796\n",
      "buying\tdisappears\t2\t3925.333107\n",
      "let\tus\t3\t3310.499278\n",
      "upper\thand\t2\t2943.499745\n",
      "commercial\tcrises\t2\t2943.499745\n",
      "various\tstages\t2\t2943.499745\n",
      "united\taction\t3\t2942.749427\n",
      "raw\tmaterial\t2\t2616.221958\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 1 and w1 not in stopword_list and w2 not in stopword_list:\n",
    "        w1_only_count = word_counts[w1] - w1_w2_count\n",
    "        w2_only_count = word_counts[w2] - w1_w2_count\n",
    "        rest_count = total - w1_only_count - w2_only_count - w1_w2_count\n",
    "        pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many\tbourgeois\t2\t49.412739\n",
      "bourgeois\tprivate\t2\t44.087627\n",
      "petty\tbourgeoisie\t2\t43.023037\n",
      "modern\tworking\t2\t41.985003\n",
      "bourgeois\tfreedom\t2\t39.732201\n",
      "revolutionary\tproletariat\t2\t35.100229\n",
      "old\tconditions\t2\t32.566311\n",
      "feudal\tproperty\t2\t31.386462\n",
      "old\tproperty\t2\t28.685615\n",
      "bourgeois\trevolution\t2\t26.136797\n",
      "modern\tbourgeoisie\t3\t21.380029\n",
      "whole\tbourgeoisie\t2\t20.752016\n",
      "revolutionary\tclass\t2\t20.224783\n",
      "bourgeois\tstate\t2\t17.063629\n",
      "every\tclass\t2\t16.075081\n",
      "bourgeois\tconditions\t3\t16.040705\n",
      "bourgeois\tform\t2\t14.680146\n",
      "one\tclass\t2\t10.562861\n",
      "bourgeois\tproduction\t2\t5.662454\n",
      "bourgeois\tclass\t3\t5.261506\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), x_2 in pair_chi_squares.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for computing mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def mutual_information(w1_w2_prob, w1_prob, w2_prob):\n",
    "    return math.log2(w1_w2_prob / (w1_prob * w2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danish\tlanguages\t1\t13.524297\n",
      "fanatics\thole\t1\t13.524297\n",
      "battles\tlies\t1\t13.524297\n",
      "egotistical\tcalculation\t1\t13.524297\n",
      "greatest\tpleasure\t1\t13.524297\n",
      "duodecimo\teditions\t1\t13.524297\n",
      "decisive\thour\t1\t13.524297\n",
      "nursery\ttale\t1\t13.524297\n",
      "czar\tmetternich\t1\t13.524297\n",
      "instinctive\tyearnings\t1\t13.524297\n",
      "numberless\tindefeasible\t1\t13.524297\n",
      "trades\tunions\t1\t13.524297\n",
      "remotest\tzones\t1\t13.524297\n",
      "establish\tconnections\t1\t13.524297\n",
      "gothic\tcathedrals\t1\t13.524297\n",
      "deep\tintuition\t1\t13.524297\n",
      "singing\tlampoons\t1\t13.524297\n",
      "proper\tserving\t1\t13.524297\n",
      "arouse\tsympathy\t1\t13.524297\n",
      "sentimental\tveil\t1\t13.524297\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 0:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productive\tforces\t9\t10.064865\n",
      "middle\tages\t7\t9.461287\n",
      "no\tlonger\t14\t8.215308\n",
      "private\tproperty\t7\t7.202369\n",
      "working\tclass\t23\t6.762457\n",
      "modern\tindustry\t11\t6.699483\n",
      "have\tbeen\t7\t6.669874\n",
      "class\tantagonisms\t11\t6.582849\n",
      "proportion\tas\t8\t6.513070\n",
      "ruling\tclass\t11\t6.475934\n",
      "can\tnot\t9\t6.453431\n",
      "just\tas\t6\t6.223563\n",
      "away\twith\t8\t6.165646\n",
      "their\town\t11\t6.138238\n",
      "petty\tbourgeois\t6\t6.020471\n",
      "middle\tclass\t6\t5.708380\n",
      "its\town\t8\t5.660885\n",
      "property\trelations\t6\t5.658048\n",
      "not\tonly\t7\t5.550292\n",
      "class\tstruggle\t6\t5.321357\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 5:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filtering out the collocations containing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\testate\t2\t12.524297\n",
      "constitution\tadapted\t2\t12.524297\n",
      "corporate\tguilds\t2\t11.939334\n",
      "laid\tbare\t2\t11.524297\n",
      "eternal\ttruths\t3\t11.524297\n",
      "distinctive\tfeature\t2\t11.354372\n",
      "torn\tasunder\t2\t11.354372\n",
      "radical\trupture\t2\t11.202369\n",
      "eighteenth\tcentury\t3\t11.202369\n",
      "immense\tmajority\t3\t11.109259\n",
      "buying\tdisappears\t2\t10.939334\n",
      "absolute\tmonarchy\t4\t10.880441\n",
      "upper\thand\t2\t10.524297\n",
      "commercial\tcrises\t2\t10.524297\n",
      "various\tstages\t2\t10.524297\n",
      "complete\tsystems\t2\t10.354372\n",
      "raw\tmaterial\t2\t10.354372\n",
      "earlier\tepochs\t2\t10.354372\n",
      "guild\tmasters\t2\t10.202369\n",
      "best\tpossible\t2\t10.202369\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 1 and w1 not in stopword_list and w2 not in stopword_list:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
